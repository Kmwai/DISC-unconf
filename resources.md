## References 
---------------------------- Disha -------------------------------
* [How We Examined Racial Discrimination in Auto Insurance Prices](https://www.propublica.org/article/minority-neighborhoods-higher-car-insurance-premiums-methodology)

* [Turns Out Algorithms Are Racist](https://newrepublic.com/article/144644/turns-algorithms-racist?utm_content=buffer7f3ea&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)

* [How I'm Fighting Bias in Algorithms (Ted Talk)](http://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms)

* [The Dark Secret at the Heart of AI](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/)

---------------------------- Bobby -------------------------------
* [AI NOW](https://ainowinstitute.org/)
* [AI NOW report](https://assets.contentful.com/8wprhhvnpfc0/1A9c3ZTCZa2KEYM64Wsc2a/8636557c5fb14f2b74b2be64c3ce0c78/_AI_Now_Institute_2017_Report_.pdf)

* [Algorithms and bias: What lenders need to know](www.whitecase.com/publications/insight/algorithms-and-bias-what-lenders-need-know)


* [WHY AI IS STILL WAITING FOR ITS ETHICS TRANSPLANT](https://www.wired.com/story/why-ai-is-still-waiting-for-its-ethics-transplant/)

---------------------------- Bernie -------------------------------
* Upcoming conference-- 
https://fatconference.org/index.html
The first FAT (Fairness Accountability Transparency in socio-technical systems) conference to be held in Feb 2018 in NYC.
FAT* is an annual conference dedicating to bringing together a diverse community to investigate and tackle issues in this emerging area. Topics of interest include, but are not limited to:

The theory and practice of fair and interpretable Machine Learning, Information Retrieval, NLP, and Computer Vision
Measurement and auditing of deployed systems
Users' experience of algorithms, and design interventions to empower users
The ethical, moral, social, and policy implications of big data and ubiquitous intelligent systems

Conference on Fairness, Accountability, and Transparency - Call for Tutorials

https://fatconference.org/2018/cftutorials.html

We are soliciting calls for two types of tutorials at FAT* 2018: hands-on tutorials and translation tutorials. Both types of tutorials will give presenters 1 hour to address technical and/or policy/law FAT* issues for a broad audience.

== Important details ==

Submission deadline: December 11, 2017, 23:59 Anywhere on Earth (AoE)
Conference date: February 23-24, 2018
Conference location: New York City

== Hands-on Tutorials ==

We envision these hands-on tutorials as being a chance for a broad audience to experiment with new software packages designed to support FAT* efforts. Tutorials should introduce the motivation for the tool, explain how the underlying technology works, and walk through an example use case of the presented software. Given our emphasis on accountability and transparency, only open-source software (licensed under GPL, Apache 2.0, MIT, BSD etc.) will be expected for the tools presented in these tutorials.

Presenters may assume that participants would arrive with their own laptop to the session and would be expected to have a basic understanding of programming, though they wouldn’t necessarily be computer scientists; the tutorial should be accessible to a beginning audience.

== Translation Tutorials==

We are interested in tutorials that aim to "translate" between disciplines; by explaining computer science concepts in a way that will be practically useful for lawyers, policy makers, and other practitioners or by explaining legal, policy, or social science concepts in a way that will guide computer scientists in future technical explorations. These tutorials should be geared towards an interested, beginning audience. Tutorials should situate the topic in the related literature and do a deeper dive explaining a specific topic.

== Application Process ==

To apply to lead a tutorial, please write a 1-2 page description of the tutorial including:

        • Title - titles should be in the format, "Hands-on Tutorial: title" or "Translation Tutorial: title" depending on the type of tutorial proposed.
        • The team - we encourage tutorials to be led by one to three people. More than three people is likely to be too chaotic.
        • A description of the topic you plan to cover.
        • A short (one paragraph) timeline of how you plan to break down the material over the hour.
        • Any critical citations. Hands-on tutorials should include a link to the open source software.
        • Hands-on tutorials only: if possible, include a short code snippet and installation instructions.
        • Any specific audio/visual needs, including projectors, microphones, etc.

== Submission Instructions ==

Submissions should be emailed in PDF format to the PC Co-chairs: Sorelle Friedler (sorelle@cs.haverford.edu) and Christo Wilson (cbw@ccs.neu.edu)

Fairness, Accountability, and Transparency in Machine Learning - http://fatml.org/

* lots of resources--
https://fatconference.org/resources.html 

* [SAP Uses Machine Learning to Find Gender Biased Job Posts](https://www.hrtechnologist.com/news/requisitionjob-posting/sap-uses-machine-learning-to-find-gender-biased-job-posts/)

* [An AI Recruiter Could Find You Your Next Job](https://www.technologyreview.com/the-download/609570/an-ai-recruiter-could-find-you-your-next-job/)

---------------------------- Zairah -------------------------------
* [DeepMind Ethics Research Group - Google](https://deepmind.com/applied/deepmind-ethics-society/research/)
  DeepMind's Ethics & Society is a research unit within DeepMind that aims to explore and better understand the real-world    
  impacts of AI.  It aims to help technologists put ethics into practice and help society anticipate and control the effects 
  of AI, by enlisting some questions around - 
  * privacy
  * transparency 
  * fairness 
  * governence and accountability
  that should be addressed throughout the life cycle of projects. 

* [Why We Launched DeepMind Ethics & Society](https://deepmind.com/blog/why-we-launched-deepmind-ethics-society/)

* [Responsible Data Science](http://www.responsibledatascience.org/)


---------------------------- Abhipsa ------------------------------
* [How do machines learning algorithms learn bias?](https://towardsdatascience.com/how-do-machine-learning-algorithms-learn-bias-555809a1decb)

* [Controlling machine learning algorithms and their biases](https://www.mckinsey.com/business-functions/risk/our-insights/controlling-machine-learning-algorithms-and-their-biases)

* [Counterfactual Fairness - Causal models capture social biases and make clear the implicit trade-off between prediction
accuracy and fairness in an unfair world](https://arxiv.org/pdf/1703.06856.pdf)

* [Attacking Discrimination in ML- google research paper](https://research.google.com/bigpicture/attacking-discrimination-in-ml/)

* [Equality Opportunity](https://drive.google.com/file/d/0B-wQVEjH9yuhanpyQjUwQS1JOTQ/view)

* [principles for accountable algorithms](https://www.fatml.org/resources/principles-for-accountable-algorithms)

-----------------------------------------------------------------------------------------

* [make algorithms accountable](https://www.nytimes.com/2016/08/01/opinion/make-algorithms-accountable.html)

* [IEEE standards for AI ethics](http://standards.ieee.org/develop/indconn/ec/autonomous_systems.html)

* [Algorithmic accountability](https://techcrunch.com/2017/04/30/algorithmic-accountability/)

* [Partnership in AI](https://www.partnershiponai.org)

* [Book: What Algorithms Want - Ed Finn](https://mitpress.mit.edu/books/what-algorithms-want)

* [Link to White Paper Containing Question Tool](https://cdt.org/issue/privacy-data/digital-decisions/)

* [Website to report bias] (https://www.ajlunited.org/fight)

* [Bias in software to predict future criminals - biased against blacks](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing)
